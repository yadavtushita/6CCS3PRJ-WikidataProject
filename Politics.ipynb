{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting SPARQLWrapper\n",
      "  Using cached SPARQLWrapper-1.8.5-py3-none-any.whl (26 kB)\n",
      "Collecting rdflib>=4.0\n",
      "  Using cached rdflib-6.1.1-py3-none-any.whl (482 kB)\n",
      "Collecting isodate\n",
      "  Using cached isodate-0.6.1-py2.py3-none-any.whl (41 kB)\n",
      "Requirement already satisfied: pyparsing in c:\\users\\tushi\\anaconda3\\lib\\site-packages (from rdflib>=4.0->SPARQLWrapper) (2.4.7)\n",
      "Requirement already satisfied: setuptools in c:\\users\\tushi\\anaconda3\\lib\\site-packages (from rdflib>=4.0->SPARQLWrapper) (49.2.0.post20200714)\n",
      "Requirement already satisfied: six in c:\\users\\tushi\\anaconda3\\lib\\site-packages (from isodate->rdflib>=4.0->SPARQLWrapper) (1.15.0)\n",
      "Installing collected packages: isodate, rdflib, SPARQLWrapper\n",
      "Successfully installed SPARQLWrapper-1.8.5 isodate-0.6.1 rdflib-6.1.1\n"
     ]
    }
   ],
   "source": [
    "# ! pip install SPARQLWrapper\n",
    "# TODO: Remember to mention in documentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "from SPARQLWrapper import SPARQLWrapper, JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the data from politics revisions\n",
    "# Contains the revisions for all the selected items\n",
    "revisions = pd.read_csv('/Users/tushi/PRJ/WikidataParsing/topics/data_with_revisions/politics_revisions.csv')\n",
    "items = pd.read_csv('/Users/tushi/PRJ/WikidataParsing/topics/data/politics.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3915164, 12)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "revisions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(414463, 3)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "items.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using SPARQL to retrieve the labels for all the items by using the corresponding qids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specifying the Wikidata SPARQL endpoint\n",
    "sparql = SPARQLWrapper(\"https://query.wikidata.org/sparql\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'head': {'vars': ['label']}, 'results': {'bindings': [{'label': {'xml:lang': 'af', 'type': 'literal', 'value': 'Albrecht Schläger'}}]}}\n"
     ]
    }
   ],
   "source": [
    "# Query to access the label for the wikidata item\n",
    "sparql.setQuery(\"\"\"\n",
    "    SELECT ?label \n",
    "    WHERE {\n",
    "      wd:Q109321 rdfs:label ?label . \n",
    "      SERVICE wikibase:label { bd:serviceParam wikibase:language \"en\". }\n",
    "      }\n",
    "    LIMIT 1\n",
    "\"\"\")\n",
    "\n",
    "# Converting result to JSON format\n",
    "sparql.setReturnFormat(JSON)\n",
    "result = sparql.query().convert()\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': {'xml:lang': 'af', 'type': 'literal', 'value': 'Albrecht Schläger'}}]\n",
      "{'label': {'xml:lang': 'af', 'type': 'literal', 'value': 'Albrecht Schläger'}}\n",
      "{'xml:lang': 'af', 'type': 'literal', 'value': 'Albrecht Schläger'}\n"
     ]
    }
   ],
   "source": [
    "print(result[\"results\"][\"bindings\"])\n",
    "print(result[\"results\"][\"bindings\"][0])\n",
    "print(result[\"results\"][\"bindings\"][0][\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Albrecht Schläger\n"
     ]
    }
   ],
   "source": [
    "print(result[\"results\"][\"bindings\"][0][\"label\"][\"value\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_item_label(qid):\n",
    "    try:        \n",
    "        # Specifying the Wikidata SPARQL endpoint\n",
    "        sparql = SPARQLWrapper(\"https://query.wikidata.org/sparql\")\n",
    "        \n",
    "        # Query to access the label for the wikidata item\n",
    "        sparql.setQuery('PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#> SELECT ?label WHERE {wd:' + qid + ' rdfs:label ?label . SERVICE wikibase:label { bd:serviceParam wikibase:language \"en\". } } LIMIT 1')\n",
    "        \n",
    "        # Converting result to JSON format\n",
    "        sparql.setReturnFormat(JSON)\n",
    "        result = sparql.query().convert()\n",
    "        \n",
    "        # result is in the form of \"bindings\" which are a list of dictionaries\n",
    "        # Accessing the value of the label \n",
    "        itemLabel = result[\"results\"][\"bindings\"][0][\"label\"][\"value\"]\n",
    "        \n",
    "        return itemLabel\n",
    "    except Exception as ex:\n",
    "        print(ex)\n",
    "        return('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Donald Trump\n",
      "0.046875\n"
     ]
    }
   ],
   "source": [
    "start = time.process_time()\n",
    "print(get_item_label(\"Q22686\"))\n",
    "print(time.process_time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP Error 429: Too Many Requests\n",
      "HTTP Error 429: Too Many Requests\n",
      "HTTP Error 429: Too Many Requests\n",
      "HTTP Error 429: Too Many Requests\n",
      "HTTP Error 429: Too Many Requests\n",
      "HTTP Error 429: Too Many Requests\n",
      "<urlopen error [WinError 10065] A socket operation was attempted to an unreachable host>\n",
      "<urlopen error [Errno 11001] getaddrinfo failed>\n",
      "<urlopen error [Errno 11001] getaddrinfo failed>\n",
      "<urlopen error [Errno 11001] getaddrinfo failed>\n",
      "<urlopen error [Errno 11001] getaddrinfo failed>\n",
      "<urlopen error [Errno 11001] getaddrinfo failed>\n",
      "<urlopen error [Errno 11001] getaddrinfo failed>\n",
      "<urlopen error [Errno 11001] getaddrinfo failed>\n",
      "<urlopen error [Errno 11001] getaddrinfo failed>\n",
      "<urlopen error [Errno 11001] getaddrinfo failed>\n",
      "<urlopen error [Errno 11001] getaddrinfo failed>\n",
      "<urlopen error [Errno 11001] getaddrinfo failed>\n",
      "<urlopen error [Errno 11001] getaddrinfo failed>\n",
      "<urlopen error [Errno 11001] getaddrinfo failed>\n",
      "<urlopen error [Errno 11001] getaddrinfo failed>\n",
      "<urlopen error [Errno 11001] getaddrinfo failed>\n",
      "<urlopen error [Errno 11001] getaddrinfo failed>\n",
      "<urlopen error [Errno 11001] getaddrinfo failed>\n",
      "<urlopen error [Errno 11001] getaddrinfo failed>\n",
      "<urlopen error [Errno 11001] getaddrinfo failed>\n",
      "<urlopen error [Errno 11001] getaddrinfo failed>\n",
      "<urlopen error [Errno 11001] getaddrinfo failed>\n",
      "<urlopen error [Errno 11001] getaddrinfo failed>\n",
      "<urlopen error [Errno 11001] getaddrinfo failed>\n",
      "<urlopen error [Errno 11001] getaddrinfo failed>\n",
      "<urlopen error [Errno 11001] getaddrinfo failed>\n",
      "<urlopen error [Errno 11001] getaddrinfo failed>\n",
      "<urlopen error [Errno 11001] getaddrinfo failed>\n",
      "<urlopen error [Errno 11001] getaddrinfo failed>\n",
      "<urlopen error [Errno 11001] getaddrinfo failed>\n",
      "<urlopen error [Errno 11001] getaddrinfo failed>\n",
      "<urlopen error [Errno 11001] getaddrinfo failed>\n",
      "<urlopen error [Errno 11001] getaddrinfo failed>\n",
      "<urlopen error [Errno 11001] getaddrinfo failed>\n",
      "<urlopen error [Errno 11001] getaddrinfo failed>\n",
      "<urlopen error [Errno 11001] getaddrinfo failed>\n",
      "<urlopen error [Errno 11001] getaddrinfo failed>\n",
      "<urlopen error [Errno 11001] getaddrinfo failed>\n",
      "<urlopen error [Errno 11001] getaddrinfo failed>\n",
      "<urlopen error [Errno 11001] getaddrinfo failed>\n",
      "<urlopen error [Errno 11001] getaddrinfo failed>\n",
      "<urlopen error [Errno 11001] getaddrinfo failed>\n",
      "<urlopen error [Errno 11001] getaddrinfo failed>\n",
      "<urlopen error [Errno 11001] getaddrinfo failed>\n",
      "<urlopen error [Errno 11001] getaddrinfo failed>\n",
      "<urlopen error [Errno 11001] getaddrinfo failed>\n",
      "<urlopen error [Errno 11001] getaddrinfo failed>\n",
      "<urlopen error [Errno 11001] getaddrinfo failed>\n",
      "<urlopen error [Errno 11001] getaddrinfo failed>\n",
      "<urlopen error [Errno 11001] getaddrinfo failed>\n",
      "<urlopen error [Errno 11001] getaddrinfo failed>\n",
      "<urlopen error [Errno 11001] getaddrinfo failed>\n",
      "<urlopen error [Errno 11001] getaddrinfo failed>\n",
      "<urlopen error [Errno 11001] getaddrinfo failed>\n",
      "<urlopen error [Errno 11001] getaddrinfo failed>\n",
      "<urlopen error [Errno 11001] getaddrinfo failed>\n",
      "<urlopen error [Errno 11001] getaddrinfo failed>\n",
      "<urlopen error [Errno 11001] getaddrinfo failed>\n",
      "<urlopen error [Errno 11001] getaddrinfo failed>\n"
     ]
    }
   ],
   "source": [
    "# Retrieiving labels for the items dataframe first \n",
    "# This will make the process quicker as compared to doing it for all revisions\n",
    "items['label'] = [get_item_label(qid) for qid in items['qid']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What all needs to be done?\n",
    "\n",
    "1. The edit type needs to be redone as multiple edge cases were discovered during thedata parsing and collection stage which were not known beforehand or from sampling 10000 revisions.\n",
    "\n",
    "- Comment - check for type such as if it is a revert, undo or if it is a predefined edit action like wbsetlabel - add:\n",
    "\n",
    "- If of type wbset...:..../.. break the string up at the first occurrence of the colon :\n",
    "\n",
    "- Then look at whether it is part of the edge cases wbsetlabeldescriptionaliases, .. etc and if not then it must be of type wbsetlabel- add, then look at the text before and after the dash. \n",
    "\n",
    "- this can probably be done by defining a method which takes in the comment, analyses it with a series of if statements, uses regex to break up the text etc and then returns 1 value for edit type or two values in a tuple for edit type and edit entity which can then be added to the dataframe using [0] and [1]\n",
    "\n",
    "2. Remove items and their respective revisions with editcount below a certain value - need to research, find a paper on edits and do it.\n",
    "\n",
    "3. Idea: could also lable the edits based on contributors - research paper whih categorised contributors into registered, anonymous and bots (already have a list of bots - just need to verify the data) \n",
    "\n",
    "4. Remove items with edits only from bots.\n",
    "\n",
    "5. Drop unecessary rows (pageid) userid might be needed to see if the contributors are the same or not - will not need if i can confirm that usernames are unique on wikidata\n",
    "\n",
    "6. Last or possibly at a later stage - convert the timestamp to a datetime object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
